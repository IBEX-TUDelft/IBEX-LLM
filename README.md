# Project Overview

This project is designed to streamline processes involving dataset preparation from log files, model fine-tuning using OpenAI's API, WebSocket connection management, and server process control. Its versatile components enable efficient handling of diverse tasks, from data manipulation to real-time communication and computational resource management.

## ðŸ“‚ Project Structure

The repository is organized as follows, providing a clear and logical layout for easy navigation and understanding:

| File/Directory      | Description |
|---------------------|-------------|
| `README.md`         | An overview of the project, its purpose, instructions for use, and the integration of an LLM agent for specific actions. |
| `constructDataset.py` | Reads `.log.json` files from `jsonFiles`, extracts "log" data, and compiles it into a JSON Lines file in `data`. |
| `data/training_set.jsonl` | Generated dataset consisting of extracted log entries, ready for model training. |
| `finetune.py`       | Interacts with the OpenAI API to fine-tune a GPT model using the prepared dataset. |
| `handler.py`        | Manages WebSocket connections for real-time server-client communication and handles specific actions as instructed by LLM agents. |
| `jsonFiles`         | Contains source `.log.json` files used for dataset creation. |
| `killer.sh`         | Shell script to terminate server processes. |
| `serverStarter.sh`  | Initializes and starts server processes. |

## ðŸš€ Usage

### Preparing the Dataset

Generate your training dataset from log files:

```bash
python constructDataset.py
```

### Fine-tuning the Model

Initiate the model fine-tuning process with OpenAI:

```bash
python finetune.py
```

### Managing WebSocket Connections

Handle WebSocket communications and specific LLM agent instructions:

```bash
python handler.py
```

### Controlling the Server

Start and stop server processes as needed:

- **To start:** `sh serverStarter.sh`
- **To stop:** `sh killer.sh`

## âœ… Requirements

Ensure your environment meets the following prerequisites:

- **Python 3.x:** The primary programming language used.
- **OpenAI API Key:** Required for `finetune.py` to access OpenAI services.
- **WebSocket Support:** Necessary for the operation of `handler.py`.


## ðŸ“Œ LLM Agent Integration

To facilitate the integration of an LLM agent for specific actions within this project, an initiating message format has been established. This format is designed to clearly communicate when and what action the LLM agent is required to perform:

```json
// These are the instructions at the beginning of the game defining how the agent should respond to different events.
"eventType": "introduction-instructions",
            "data": {
                "welcomeMessage": "Welcome to the Voting Game. You are now participating as an LLM agent.",
                "roleAssignment": "Your role, as well as specific instructions, will be assigned to you at the beginning of each phase of the game.",
                "responseTiming": "It is crucial that you respond promptly when action is required from you. Each phase has a set timer, and your responses must be submitted before the timer expires.",
                "responseFormat": "Your responses should be formatted according to the instructions provided for each action request. Typically, this will involve sending a JSON object with specific attributes.",
                "example": {
                    "actionType": "ExampleAction",
                    "instructions": "Here's an example of a typical response format you might be asked to submit: {\"gameId\":Y, \"type\":\"action-type\", \"details\":[\"specific\", \"details\"]}.",
                    "actionRequiredBy": "Remember, prompt action is required. Failure to respond in time may affect the game's outcome.",
                    "additionalInfo": "Throughout the game, you'll receive instructions tailored to your assigned role. Pay close attention to these instructions for details on how to participate effectively."
                }

// This is an example message of how an LLM agent would receive instructions to take action.
  "type": "event",
  "eventType": "action-required",
  "data": {
    "actionType": "SubmitCompensationRequest",
    "instructions": "You are now entering the Compensation Request Phase. Review the project proposals and submit your compensation request. Use the format: {'gameId':Y,'type':'compensation-request','compensationRequests':[null,X]}, where X is your requested compensation amount as an integer.",
    "deadline": "You must submit your request before the timer ends at [timestamp].",
    "format": "{'gameId':Y,'type':'compensation-request','compensationRequests':[null,X]}",
    "actionRequiredBy": "[timestamp]",
    "additionalInfo": "This phase is critical for negotiating compensation based on the project proposals. Your timely and accurate submission is essential."
  }
}
```

This message format is an example of what the LLM agent receives all necessary details to take action, including the action type, detailed instructions, deadlines, and the format for submissions. This integration is pivotal for automating and streamlining specific tasks within the project, particularly in phases requiring precise and timely submissions.

## ðŸ“š Contributing

TODO
